from fastapi import FastAPI, Request
from fastapi.responses import HTMLResponse
from fastapi.templating import Jinja2Templates
from datetime import datetime
import clickhouse_connect
import mysql.connector
from fpds.config import DB_CONFIG

# ðŸ“‚ ÐŸÑƒÑ‚ÑŒ Ðº HTML-ÑˆÐ°Ð±Ð»Ð¾Ð½Ð°Ð¼
templates = Jinja2Templates(
    directory="/Users/iliaoborin/fpds/src/web/templates")

# ðŸš€ FastAPI Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ
app = FastAPI()

# ðŸ”Œ ÐšÐ»Ð¸ÐµÐ½Ñ‚ ClickHouse
client = clickhouse_connect.get_client(host="localhost", port=8123)


def get_db_connection():
    """ÐŸÐ¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ Ðº MySQL."""
    try:
        return mysql.connector.connect(**DB_CONFIG)
    except mysql.connector.Error as e:
        print(f"âš ï¸ Database connection error: {e}")
        return None


@app.get("/contract/{contract_id}")
async def get_contract(contract_id: str):
    query = f"SELECT * FROM fpds_clickhouse.raw_contracts WHERE id = toUUID('{contract_id}') LIMIT 1"
    result = client.query(query)

    if not result.result_rows:
        return {"error": "Not found"}

    # Ð¤Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐµÐ¼ ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ Ð¸ ÑƒÐ±Ð¸Ñ€Ð°ÐµÐ¼ None Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ
    contract_data = dict(zip(result.column_names, result.result_rows[0]))
    filtered_data = {key: value for key,
                     value in contract_data.items() if value is not None}

    return filtered_data


@app.get("/mutations")
async def list_mutations():
    """Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ ÑÐ¿Ð¸ÑÐ¾Ðº Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ñ… Ð¼ÑƒÑ‚Ð°Ñ†Ð¸Ð¹ Ð² ClickHouse."""
    query = """
    SELECT mutation_id, command, is_done, is_killed
    FROM system.mutations
    WHERE table = 'raw_contracts' AND database = 'fpds_clickhouse'
    """
    result = client.query(query)
    mutations = [dict(zip(result.column_names, row))
                 for row in result.result_rows]
    return {"mutations": mutations}


@app.get("/", response_class=HTMLResponse)
async def fpds_dashboard(request: Request):
    # --- Ð—Ð°Ð¿Ñ€Ð¾Ñ Ðº ClickHouse ---
    ch_query = """
        SELECT 
            partition_date, 
            COUNT(*) as count
        FROM fpds_clickhouse.raw_contracts
        GROUP BY partition_date
        ORDER BY partition_date
    """
    ch_result = client.query(ch_query)

    # Ð¤Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ ClickHouse
    clickhouse_data = {}
    for row in ch_result.result_rows:
        partition_date, count = row
        # partition_date â€” ÑÑ‚Ð¾ Ð¾Ð±ÑŠÐµÐºÑ‚ date
        date_str = partition_date.strftime("%Y-%m-%d")
        clickhouse_data[date_str] = count

    # --- Ð—Ð°Ð¿Ñ€Ð¾Ñ Ðº MySQL ---
    mysql_data = {}
    db_conn = get_db_connection()
    if db_conn:
        cursor = db_conn.cursor()
        mysql_query = """
            SELECT DATE(signed_date) as date, SUM(records) as count
            FROM signed_date_records
            GROUP BY date
        """
        cursor.execute(mysql_query)
        mysql_results = cursor.fetchall()
        for row in mysql_results:
            date_val, count = row
            date_str = date_val.strftime("%Y-%m-%d")
            mysql_data[date_str] = count
        cursor.close()
        db_conn.close()

    # --- Ð¡Ñ€Ð°Ð²Ð½ÐµÐ½Ð¸Ðµ Ð´Ð°Ð½Ð½Ñ‹Ñ… ---
    all_dates = set(clickhouse_data.keys()).union(mysql_data.keys())
    comparison = []
    for date in sorted(all_dates):
        ch_count = clickhouse_data.get(date, 0)
        mysql_count = mysql_data.get(date, 0)
        difference = ch_count - mysql_count
        comparison.append({
            "date": date,
            "clickhouse_count": ch_count,
            "mysql_count": mysql_count,
            "difference": difference
        })

    return templates.TemplateResponse("main.html", {
        "request": request,
        "comparison": comparison
    })


def format_bytes(size):
    """Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€ÑƒÐµÑ‚ Ð±Ð°Ð¹Ñ‚Ñ‹ Ð² KB, MB, GB Ð¸ Ñ‚.Ð´."""
    power = 1024
    n = 0
    power_labels = ['B', 'KB', 'MB', 'GB', 'TB']
    while size >= power and n < len(power_labels) - 1:
        size /= power
        n += 1
    return f"{size:.2f} {power_labels[n]}"
    

@app.get("/clickhouse", response_class=HTMLResponse)
async def clickhouse_info(request: Request):
    """ÐŸÐ°Ð½ÐµÐ»ÑŒ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð° ClickHouse."""

    # 1. Ð’ÐµÑ€ÑÐ¸Ñ ClickHouse
    version = client.query("SELECT version()").result_rows[0][0]

    # 2. Ð’Ð°Ð¶Ð½Ñ‹Ðµ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸
    settings_query = """
        SELECT name, value
        FROM system.settings
        WHERE name IN ('max_memory_usage', 'max_threads', 'max_server_memory_usage', 'max_memory_usage_for_all_queries', 'mark_cache_size', 'uncompressed_cache_size')
    """
    settings_result = client.query(settings_query)
    settings = {name: value for name, value in settings_result.result_rows}

    # 3. ÐÐºÑ‚Ð¸Ð²Ð½Ñ‹Ðµ Ð·Ð°Ð¿Ñ€Ð¾ÑÑ‹
    active_queries = client.query(
        "SELECT count() FROM system.processes").result_rows[0][0]

    # 4. Ð Ð°Ð·Ð¼ÐµÑ€ Ð±Ð°Ð·Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ…
    db_size_result = client.query("""
        SELECT sum(bytes_on_disk) AS total_bytes, sum(rows) AS total_rows
        FROM system.parts
        WHERE database = 'fpds_clickhouse'
    """)
    total_bytes, total_rows = db_size_result.result_rows[0]
    formatted_total_bytes = format_bytes(total_bytes)

    # 5. ÐÐ¿Ñ‚Ð°Ð¹Ð¼ ÑÐµÑ€Ð²ÐµÑ€Ð°
    uptime_result = client.query(
        "SELECT formatReadableTimeDelta(uptime())").result_rows[0][0]

    # 6. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð´Ð¸ÑÐºÐ¾Ð²
    disks_query = """
        SELECT name, free_space, total_space
        FROM system.disks
    """
    disks_result = client.query(disks_query)
    disks = [{
        "name": row[0],
        "free_space": format_bytes(row[1]),
        "total_space": format_bytes(row[2])
    } for row in disks_result.result_rows]

    # 7. Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° CPU
    cpu_query = """
        SELECT metric, value
        FROM system.metrics
        WHERE metric LIKE '%CPU%'
    """
    cpu_result = client.query(cpu_query)
    cpu_metrics = {metric: value for metric, value in cpu_result.result_rows}

    # 8. ÐžÑˆÐ¸Ð±ÐºÐ¸ ÑÐµÑ€Ð²ÐµÑ€Ð°
    errors_result = client.query("""
    SELECT value
    FROM system.events
    WHERE event = 'ExceptionWhileProcessing'
    """)
    server_errors = errors_result.result_rows[0][0] if errors_result.result_rows else 0

    # 9. Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° ÐºÐµÑˆÐ° (Ð±ÐµÐ· Ð¿Ð°Ð´ÐµÐ½Ð¸Ñ, ÐµÑÐ»Ð¸ Ð½ÐµÑ‚ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹)
    try:
        cache_query = """
            SELECT cache_name, hits, misses, round(hits / (hits + misses + 0.001), 3) as hit_ratio FROM system.cache_diagnostics
        """
        cache_result = client.query(cache_query)
        cache_stats = [{
            "cache_name": row[0],
            "hits": row[1],
            "misses": row[2],
            "hit_ratio": row[3]
        } for row in cache_result.result_rows]
    except Exception as e:
        print(f"âš ï¸ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ ÐºÐµÑˆ-ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ: {e}")
        cache_stats = []  # ÐŸÑƒÑÑ‚Ð¾Ð¹ ÑÐ¿Ð¸ÑÐ¾Ðº, Ñ‡Ñ‚Ð¾Ð±Ñ‹ ÑˆÐ°Ð±Ð»Ð¾Ð½ Ð½Ðµ ÑƒÐ¿Ð°Ð»

    return templates.TemplateResponse("clickhouse.html", {
        "request": request,
        "version": version,
        "settings": settings,
        "active_queries": active_queries,
        "total_bytes": formatted_total_bytes,
        "total_rows": total_rows,
        "uptime": uptime_result,
        "disks": disks,
        "cpu_metrics": cpu_metrics,
        "server_errors": server_errors,
        "cache_stats": cache_stats
    })

# Ð—Ð°Ð¿ÑƒÑÐº:
# uvicorn src.api.app:app --reload
# http://127.0.0.1:8000/contract/<uuid>
# http://127.0.0.1:8000/mutations
