import asyncio
import json
import mysql.connector
import click
import os
import time
import sys
# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è ClickHouse
from fpds.cli.parts.columns import columns
# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é `convert_bool`, –∫–æ—Ç–æ—Ä–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –±—É–ª–µ–≤—ã –∑–Ω–∞—á–µ–Ω–∏—è ("true"/"false") –≤ 1/0
from fpds.cli.parts.utils import convert_bool
# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –±—É–ª–µ–≤—ã—Ö –ø–æ–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –∫–∞–∫ 1/0
from fpds.cli.parts.bool_fields import bool_fields
# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞
from fpds.cli.parts.contract_parser import extract_contract_data
from fpds.cli.parts.utils import log_missing_keys
from fpds.cli.parts.utils import process_booleans

from datetime import datetime, timedelta
from itertools import chain
from pathlib import Path
from click import UsageError

from fpds import fpdsRequest
from fpds.utilities import validate_kwarg
from fpds.config import DB_CONFIG


def get_db_connection():
    """Creates and returns a database connection"""
    try:
        conn = mysql.connector.connect(**DB_CONFIG)
        return conn
    except mysql.connector.Error as e:
        click.echo(f"‚ö†Ô∏è Database connection error: {e}")
        return None


def log_parsing_result(parsed_date, file_path, status, update=False):
    """Logs the parsing result in the database"""
    conn = get_db_connection()
    if conn is None:
        click.echo("‚ö†Ô∏è Unable to connect to the database")
        return False

    cursor = conn.cursor()

    # Colored statuses
    status_colors = {
        "completed": "green",
        "pending": "yellow",
        "failed": "red"
    }

    colored_status = click.style(status, fg=status_colors.get(status, "white"))

    if update:
        cursor.execute(
            "UPDATE parser_stage SET status = %s, updated_at = NOW() WHERE parsed_date = %s",
            (status, parsed_date)
        )
        conn.commit()
        click.echo(
            f"üìù Parsing status updated for {parsed_date}: {colored_status}")
    else:
        cursor.execute(
            "SELECT 1 FROM parser_stage WHERE parsed_date = %s", (parsed_date,))
        exists = cursor.fetchone()

        if exists:
            click.echo(
                f"‚ö†Ô∏è Data for {parsed_date} already exists in the database. Skipping download.")
            conn.close()
            return False
        else:
            cursor.execute(
                "INSERT INTO parser_stage (parsed_date, file_path, status, created_at, updated_at) "
                "VALUES (%s, %s, %s, NOW(), NOW())",
                (parsed_date, file_path, status)
            )
            conn.commit()
            click.echo(
                f"‚úÖ Data for {parsed_date} successfully added to the database with status: {colored_status}")

    conn.close()
    return True


@click.command()
@click.argument("date")
def parse_clickhouse(date):
    """
    –ü–∞—Ä—Å–∏—Ç FPDS Atom feed –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç JSON-–∫–æ–Ω—Ç—Ä–∞–∫—Ç—ã –≤ ClickHouse —Å —Ä–∞–∑–±–∏–µ–Ω–∏–µ–º –Ω–∞ —á–∞–Ω–∫–∏.

    –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
        $ fpds parse clickhouse all
    """
    import clickhouse_connect

    # ‚úÖ –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞
    BATCH_SIZE = 1000
    batch = []
    total_inserted = 0

    client = clickhouse_connect.get_client(
        host="localhost", port=8123, database="fpds_clickhouse"
    )

    conn = get_db_connection()
    if conn is None:
        click.echo("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ MySQL.")
        return

    cursor = conn.cursor()

    if date.lower() == "all":
        click.echo("üîç –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—É—é –¥–∞—Ç—É...")

        cursor.execute("""
            SELECT MAX(parsed_date) FROM parser_stage WHERE status = 'completed'
        """)
        last_parsed_date = cursor.fetchone()[0]

        if last_parsed_date is None:
            click.echo("‚ö†Ô∏è –ù–µ—Ç –∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π. –ù–∞—á–∏–Ω–∞–µ–º —Å 1957-09-30.")
            last_parsed_date = datetime(1957, 9, 30)  # –°—Ç–∞—Ä—Ç —Å 1957 –≥–æ–¥–∞
        else:
            last_parsed_date = datetime.strptime(
                str(last_parsed_date), "%Y-%m-%d")

        next_parsing_date = last_parsed_date + timedelta(days=1)
        date = next_parsing_date.strftime("%Y/%m/%d")

        click.echo(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ —Å {date}")

    while True:
        year, month, day = date.split("/")
        DATA_FILE = Path(os.getenv(
            "DATA_DIR", "/Users/iliaoborin/fpds/data/")) / str(year) / f"{month}_{day}.json"

        if not log_parsing_result(date, str(DATA_FILE), "completed"):
            next_parsing_date = datetime.strptime(
                date, "%Y/%m/%d") + timedelta(days=1)
            date = next_parsing_date.strftime("%Y/%m/%d")
            year, month, day = date.split("/")
            click.echo(
                f"üîÑ –î–∞–Ω–Ω—ã–µ –∑–∞ {date} —É–∂–µ –µ—Å—Ç—å. –ü—Ä–æ–±—É–µ–º —Å–ª–µ–¥—É—é—â—É—é –¥–∞—Ç—É...")
            continue

        break

    formatted_date = f"SIGNED_DATE=[{date},{date}]"
    params = [formatted_date.split("=")]

    if not params:
        raise UsageError("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –ø–∞—Ä–∞–º–µ—Ç—Ä")

    params_kwargs = dict(params)
    click.echo(f"üîç –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è FPDS: {params_kwargs}")

    request = fpdsRequest(**params_kwargs, cli_run=True)
    click.echo("üåê –ü–æ–ª—É—á–∞–µ–º –∑–∞–ø–∏—Å–∏ FPDS...")

    try:
        data = asyncio.run(request.data())
        records = list(chain.from_iterable(data))

        DATA_DIR = Path(
            os.getenv("DATA_DIR", "/Users/iliaoborin/fpds/data/")) / str(year)
        DATA_DIR.mkdir(parents=True, exist_ok=True)

        with open(DATA_FILE, "w") as outfile:
            json.dump(records, outfile)

        click.echo(f"üìÑ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(records)} –∑–∞–ø–∏—Å–µ–π –≤ JSON: {DATA_FILE}")

        if not records:
            click.echo(
                f"‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –∑–∞ {date}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –≤ ClickHouse.")
            os.remove(DATA_FILE)
            return

        # ‚úÖ –ó–∞–≥—Ä—É–∂–∞–µ–º JSON –≤ ClickHouse —á–∞–Ω–∫–∞–º–∏ (–ø–æ 5000 –∑–∞–ø–∏—Å–µ–π)
        for i in range(0, len(records), BATCH_SIZE):
            batch = []

            for contract in records[i: i + BATCH_SIZE]:
                signed_date = (
                    contract.get("content__award__relevantContractDates__signedDate")
                    or contract.get("content__IDV__relevantContractDates__signedDate")
                    or contract.get("content__OtherTransactionAward__contractDetail__relevantContractDates__signedDate")
                    or contract.get("content__OtherTransactionIDV__contractDetail__relevantContractDates__signedDate")
                )

                partition_year = datetime.strptime(
                    signed_date, "%Y-%m-%d %H:%M:%S").year if signed_date else None

                # üîÑ –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –±—É–ª–µ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º
                contract = process_booleans(contract, bool_fields)

                # üì¶ –ò–∑–≤–ª–µ–∫–∞–µ–º –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞ –ø–µ—Ä–µ–¥ –≤—Å—Ç–∞–≤–∫–æ–π –≤ ClickHouse
                contract_data = extract_contract_data(contract, partition_year)

                # üîç –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
                log_missing_keys(contract, columns, DATA_FILE)

                batch.append(contract_data)



            # –í—Å—Ç–∞–≤–∫–∞ —á–∞–Ω–∫–∞ –≤ ClickHouse
            if batch:
                client.insert("raw_contracts", batch, column_names=columns)
                total_inserted += len(batch)
                sys.stdout.write(
                    f"\r‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {total_inserted} –∫–æ–Ω—Ç—Ä–∞–∫—Ç–æ–≤ –≤ ClickHouse")
                sys.stdout.flush()

                # –û—á–∏—â–∞–µ–º batch –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏
                batch.clear()
                time.sleep(1)

        log_parsing_result(date, str(DATA_FILE), "completed", update=True)

    except Exception as e:
        log_parsing_result(date, str(DATA_FILE), "failed", update=True)
        click.echo(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ: {e}")

    conn.close()
