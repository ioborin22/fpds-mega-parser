import json
import clickhouse_connect
import gc
import time
import mysql.connector
from pathlib import Path
from datetime import datetime
from fpds.cli.parts.utils import process_booleans, log_missing_keys
from fpds.cli.parts.contract_parser import extract_contract_data
from fpds.cli.parts.columns import columns
from fpds.cli.parts.bool_fields import bool_fields
from fpds.config import DB_CONFIG


# üìå –ù–∞—Å—Ç—Ä–æ–π–∫–∏
BATCH_SIZE = 1000  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π –≤ –±–∞—Ç—á–µ

# ‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ ClickHouse
print("üîÑ –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ ClickHouse...")
try:
    client = clickhouse_connect.get_client(
        host="localhost", port=8123, database="fpds_clickhouse"
    )
    print("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ!")
except Exception as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {e}")
    exit(1)


def get_db_connection():
    """–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ MySQL."""
    try:
        return mysql.connector.connect(**DB_CONFIG)
    except mysql.connector.Error as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î: {e}")
        return None


def get_next_file():
    """–ü–æ–ª—É—á–∞–µ—Ç —Å–ª–µ–¥—É—é—â–∏–π —Ñ–∞–π–ª –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑ MySQL."""
    conn = get_db_connection()
    if not conn:
        return None

    cursor = conn.cursor(dictionary=True)
    query = """
    SELECT id, signed_date, record_count, inserted_records, file_path, status
    FROM insert_json_clickhouse
    WHERE status = 'file_found'
    ORDER BY signed_date ASC
    LIMIT 1;
    """
    cursor.execute(query)
    file_data = cursor.fetchone()
    cursor.close()
    conn.close()

    if file_data:
        print(
            f"üìÇ –ù–∞–π–¥–µ–Ω —Ñ–∞–π–ª –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏: {file_data['file_path']} ({file_data['record_count']} –∑–∞–ø–∏—Å–µ–π)")
    return file_data


def update_status(file_id, status, inserted_records=0):
    """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å—Ç–∞—Ç—É—Å —Ñ–∞–π–ª–∞ –≤ MySQL."""
    conn = get_db_connection()
    if not conn:
        return

    cursor = conn.cursor()
    query = """
    UPDATE insert_json_clickhouse
    SET status = %s, inserted_records = %s, updated_at = NOW()
    WHERE id = %s;
    """
    cursor.execute(query, (status, inserted_records, file_id))
    conn.commit()
    cursor.close()
    conn.close()
    print(f"üìå –°—Ç–∞—Ç—É—Å –æ–±–Ω–æ–≤–ª–µ–Ω: {status}")


def process_data_and_insert(file_data):
    """–ß–∏—Ç–∞–µ—Ç JSON –∏ –≤—Å—Ç–∞–≤–ª—è–µ—Ç –≤ ClickHouse"""
    file_path = Path(file_data["file_path"])
    file_id = file_data["id"]
    expected_records = file_data["record_count"]
    inserted_records = file_data["inserted_records"]

    if inserted_records >= expected_records:
        print(f"‚úÖ –í—Å–µ –∑–∞–ø–∏—Å–∏ —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –¥–ª—è {file_path}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º.")
        update_status(file_id, "clickhouse_loaded", inserted_records)
        return

    print(f"üìñ –û—Ç–∫—Ä—ã–≤–∞–µ–º JSON-—Ñ–∞–π–ª: {file_path}")

    try:
        with open(file_path, "r") as f:
            records = json.load(f)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {file_path}: {e}")
        update_status(file_id, "clickhouse_load_failed")
        return

    if not records:
        print("‚ö†Ô∏è –§–∞–π–ª –ø—É—Å—Ç! –ü—Ä–æ–ø—É—Å–∫–∞–µ–º.")
        update_status(file_id, "clickhouse_load_failed")
        return

    print(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(records)} –∫–æ–Ω—Ç—Ä–∞–∫—Ç–æ–≤. –ó–∞–≥—Ä—É–∂–∞–µ–º...")

    total_inserted = inserted_records
    missing_keys = set()

    for i in range(inserted_records, len(records), BATCH_SIZE):
        batch = []
        for contract in records[i:i + BATCH_SIZE]:
            contract = {k: v for k, v in contract.items()
                        if k in columns or str(v).strip()}  # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≥–æ–¥, –º–µ—Å—è—Ü, –¥–µ–Ω—å
            signed_date_keys = [
                "content__award__relevantContractDates__signedDate",
                "content__IDV__relevantContractDates__signedDate",
                "content__OtherTransactionAward__contractDetail__relevantContractDates__signedDate",
                "content__OtherTransactionIDV__contractDetail__relevantContractDates__signedDate",
            ]
            signed_date = next((contract[k] for k in signed_date_keys if k in contract and contract[k]), None)
            if not signed_date:
                raise ValueError(
                    f"‚ùå –û—à–∏–±–∫–∞! –í –∫–æ–Ω—Ç—Ä–∞–∫—Ç–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç `signed_date`. –ö–æ–Ω—Ç—Ä–∞–∫—Ç: {json.dumps(contract, indent=2)}")

            # –†–∞–∑–±–∏–≤–∞–µ–º —Å—Ç—Ä–æ–∫—É –¥–∞—Ç—ã "YYYY-MM-DD HH:MM:SS" –∏ –∏–∑–≤–ª–µ–∫–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è
            date_parts = signed_date.split(" ")[0].split("-")  # –ë–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ "YYYY-MM-DD"
            partition_year = int(date_parts[0])
            partition_month = int(date_parts[1])
            partition_day = int(date_parts[2])
            # üîÑ –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –±—É–ª–µ–≤—ã –∑–Ω–∞—á–µ–Ω–∏—è
            contract = process_booleans(contract, bool_fields)

            # üì¶ –§–æ—Ä–º–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
            contract_data = extract_contract_data(
                contract, partition_year, partition_month, partition_day)

            # üìå –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å
            excluded_keys = {
                "content__award__contractData__GFE-GFP",
                "content__award__contractData__GFE-GFP__description",
                "content__IDV__contractData__GFE-GFP",
                "content__IDV__contractData__GFE-GFP__description"
            }
            # ‚ö†Ô∏è –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –Ω–æ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ `columns`
            extra_keys = {key for key in set(contract.keys()) - set(columns) if key not in excluded_keys}
            if extra_keys:
                missing_keys.update(extra_keys)

            batch.append(contract_data)

        # üöÄ –í—Å—Ç–∞–≤–∫–∞ –≤ ClickHouse
        if batch:
            # üîπ –í—Å—Ç–∞–≤–∫–∞ –≤ ClickHouse
            client.insert("raw_contracts", batch, column_names=columns)
            total_inserted += len(batch)
            print(f"‚úÖ –í—Å—Ç–∞–≤–ª–µ–Ω–æ {total_inserted} –∑–∞–ø–∏—Å–µ–π.")
            gc.collect()
            time.sleep(3)  # –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ–º –ø–µ—Ä–µ–≥—Ä—É–∑–∫—É

        # üîÑ –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –≤ MySQL –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–π –≤—Å—Ç–∞–≤–∫–∏
        update_status(file_id, "clickhouse_loaded", total_inserted)

    # üîî –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∑–∞–≥—Ä—É–∂–µ–Ω—ã –ª–∏ –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
    if total_inserted >= expected_records:
        update_status(file_id, "clickhouse_loaded", total_inserted)
    else:
        update_status(file_id, "clickhouse_load_failed", total_inserted)

    # üîî –í—ã–≤–æ–¥–∏–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ –Ω–æ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
    if missing_keys:
        print("‚ö†Ô∏è –ù–∞–π–¥–µ–Ω—ã –Ω–æ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –≤ JSON, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ `columns`:")
        for key in missing_keys:
            print(f"  - {key}")


# üîÑ –ó–∞–ø—É—Å–∫
if __name__ == "__main__":
    file_data = get_next_file()

    if file_data:
        process_data_and_insert(file_data)
    else:
        print("üéâ –ù–µ—Ç —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏. –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã.")
