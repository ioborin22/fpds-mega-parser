import json
import clickhouse_connect
import gc
import time
import mysql.connector
from pathlib import Path
from datetime import datetime
from fpds.cli.parts.utils import process_booleans, log_missing_keys
from fpds.cli.parts.contract_parser import extract_contract_data
from fpds.cli.parts.columns import columns
from fpds.cli.parts.bool_fields import bool_fields
from fpds.config import DB_CONFIG


def insert_batch_with_retry(client, table, batch, columns, initial_wait=10, wait_increment=10):
    """
    ĞŸÑ‹Ñ‚Ğ°ĞµÑ‚ÑÑ Ğ²ÑÑ‚Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ² ClickHouse. Ğ•ÑĞ»Ğ¸ Ğ²Ğ¾Ğ·Ğ½Ğ¸ĞºĞ°ĞµÑ‚ Ğ¾ÑˆĞ¸Ğ±ĞºĞ° MEMORY_LIMIT_EXCEEDED,
    Ğ´ĞµĞ»Ğ°ĞµÑ‚ Ğ¿Ğ°ÑƒĞ·Ñƒ (Ñ Ğ½Ğ°Ñ‡Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¼ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸ĞµĞ¼ initial_wait ÑĞµĞºÑƒĞ½Ğ´, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ¾Ğµ ÑƒĞ²ĞµĞ»Ğ¸Ñ‡Ğ¸Ğ²Ğ°ĞµÑ‚ÑÑ Ğ½Ğ° wait_increment ÑĞµĞºÑƒĞ½Ğ´
    Ğ¿Ñ€Ğ¸ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ Ğ½Ğ¾Ğ²Ğ¾Ğ¹ Ğ¾ÑˆĞ¸Ğ±ĞºĞµ) Ğ¸ Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€ÑĞµÑ‚ Ğ¿Ğ¾Ğ¿Ñ‹Ñ‚ĞºÑƒ.
    
    :param client: ĞºĞ»Ğ¸ĞµĞ½Ñ‚ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ Ğº ClickHouse
    :param table: Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ‹ Ğ´Ğ»Ñ Ğ²ÑÑ‚Ğ°Ğ²ĞºĞ¸
    :param batch: Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ»Ñ Ğ²ÑÑ‚Ğ°Ğ²ĞºĞ¸ (Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€, ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹)
    :param columns: ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğ¹ ĞºĞ¾Ğ»Ğ¾Ğ½Ğ¾Ğº
    :param initial_wait: Ğ½Ğ°Ñ‡Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ²Ñ€ĞµĞ¼Ñ Ğ¾Ğ¶Ğ¸Ğ´Ğ°Ğ½Ğ¸Ñ Ğ² ÑĞµĞºÑƒĞ½Ğ´Ğ°Ñ… (Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ 10)
    :param wait_increment: Ğ²ĞµĞ»Ğ¸Ñ‡Ğ¸Ğ½Ğ° ÑƒĞ²ĞµĞ»Ğ¸Ñ‡ĞµĞ½Ğ¸Ñ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸ Ğ¾Ğ¶Ğ¸Ğ´Ğ°Ğ½Ğ¸Ñ Ğ¿Ñ€Ğ¸ Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€Ğ½Ğ¾Ğ¹ Ğ¾ÑˆĞ¸Ğ±ĞºĞµ (Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ 10)
    """
    wait_time = initial_wait
    while True:
        try:
            client.insert(table, batch, column_names=columns)
            break  # Ğ•ÑĞ»Ğ¸ Ğ²ÑÑ‚Ğ°Ğ²ĞºĞ° ÑƒÑĞ¿ĞµÑˆĞ½Ğ°, Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ¸Ğ¼ Ğ¸Ğ· Ñ†Ğ¸ĞºĞ»Ğ°
        except Exception as e:
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ Ğ»Ğ¸ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ Ğ¾Ğ± Ğ¾ÑˆĞ¸Ğ±ĞºĞµ "MEMORY_LIMIT_EXCEEDED"
            if "MEMORY_LIMIT_EXCEEDED" in str(e):
                print(
                    f"âš ï¸ ĞŸÑ€ĞµĞ²Ñ‹ÑˆĞµĞ½ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸. Ğ–Ğ´ĞµĞ¼ {wait_time} ÑĞµĞºÑƒĞ½Ğ´ Ğ¿ĞµÑ€ĞµĞ´ Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€Ğ½Ğ¾Ğ¹ Ğ¿Ğ¾Ğ¿Ñ‹Ñ‚ĞºĞ¾Ğ¹...")
                time.sleep(wait_time)
                wait_time += wait_increment
            else:
                # Ğ•ÑĞ»Ğ¸ Ğ¾ÑˆĞ¸Ğ±ĞºĞ° Ğ½Ğµ ÑĞ²ÑĞ·Ğ°Ğ½Ğ° Ñ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚Ğ¾Ğ¼ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸, Ğ¿Ñ€Ğ¾Ğ±Ñ€Ğ°ÑÑ‹Ğ²Ğ°ĞµĞ¼ ĞµÑ‘ Ğ´Ğ°Ğ»ÑŒÑˆĞµ
                raise


# ğŸ“Œ ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸
BATCH_SIZE = 1000  # ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹ Ğ² Ğ±Ğ°Ñ‚Ñ‡Ğµ

# âœ… ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğº ClickHouse
print("ğŸ”„ ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğº ClickHouse...")
try:
    client = clickhouse_connect.get_client(
        host="localhost", port=8123, database="fpds_clickhouse"
    )
    print("âœ… ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾!")
except Exception as e:
    print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ: {e}")
    exit(1)


def get_db_connection():
    """ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğº MySQL."""
    try:
        return mysql.connector.connect(**DB_CONFIG)
    except mysql.connector.Error as e:
        print(f"âš ï¸ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ Ğº Ğ‘Ğ”: {e}")
        return None


def get_next_file():
    """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğ¹ Ñ„Ğ°Ğ¹Ğ» Ğ´Ğ»Ñ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ¸Ğ· MySQL."""
    conn = get_db_connection()
    if not conn:
        return None

    cursor = conn.cursor(dictionary=True)
    query = """
    SELECT id, signed_date, record_count, inserted_records, file_path, status
    FROM insert_json_clickhouse
    WHERE status = 'file_found'
    ORDER BY signed_date ASC
    LIMIT 1;
    """
    cursor.execute(query)
    file_data = cursor.fetchone()
    cursor.close()
    conn.close()

    if file_data:
        print(
            f"ğŸ“‚ ĞĞ°Ğ¹Ğ´ĞµĞ½ Ñ„Ğ°Ğ¹Ğ» Ğ´Ğ»Ñ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸: {file_data['file_path']} ({file_data['record_count']} Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹)")
    return file_data


def update_status(file_id, status, inserted_records=0):
    """ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµÑ‚ ÑÑ‚Ğ°Ñ‚ÑƒÑ Ñ„Ğ°Ğ¹Ğ»Ğ° Ğ² MySQL."""
    conn = get_db_connection()
    if not conn:
        return

    cursor = conn.cursor()
    query = """
    UPDATE insert_json_clickhouse
    SET status = %s, inserted_records = %s, updated_at = NOW()
    WHERE id = %s;
    """
    cursor.execute(query, (status, inserted_records, file_id))
    conn.commit()
    cursor.close()
    conn.close()
    print(f"ğŸ“Œ Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½: {status}")


def process_data_and_insert(file_data):
    """Ğ§Ğ¸Ñ‚Ğ°ĞµÑ‚ JSON Ğ¸ Ğ²ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ² ClickHouse"""
    file_path = Path(file_data["file_path"])
    file_id = file_data["id"]
    expected_records = file_data["record_count"]
    inserted_records = file_data["inserted_records"]

    if inserted_records >= expected_records:
        print(f"âœ… Ğ’ÑĞµ Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸ ÑƒĞ¶Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ñ‹ Ğ´Ğ»Ñ {file_path}, Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼.")
        update_status(file_id, "clickhouse_loaded", inserted_records)
        return

    print(f"ğŸ“– ĞÑ‚ĞºÑ€Ñ‹Ğ²Ğ°ĞµĞ¼ JSON-Ñ„Ğ°Ğ¹Ğ»: {file_path}")

    try:
        with open(file_path, "r") as f:
            records = json.load(f)
    except Exception as e:
        print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ñ‡Ñ‚ĞµĞ½Ğ¸Ñ {file_path}: {e}")
        update_status(file_id, "clickhouse_load_failed")
        return

    if not records:
        print("âš ï¸ Ğ¤Ğ°Ğ¹Ğ» Ğ¿ÑƒÑÑ‚! ĞŸÑ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼.")
        update_status(file_id, "clickhouse_load_failed")
        return

    print(f"ğŸ“Š ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ {len(records)} ĞºĞ¾Ğ½Ñ‚Ñ€Ğ°ĞºÑ‚Ğ¾Ğ². Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼...")

    total_inserted = inserted_records

    for i in range(inserted_records, len(records), BATCH_SIZE):
        batch = []
        for contract in records[i:i + BATCH_SIZE]:
            contract = {k: v for k, v in contract.items()
                        if k in columns or str(v).strip()}  # Ğ£Ğ´Ğ°Ğ»ÑĞµĞ¼ Ğ¿ÑƒÑÑ‚Ñ‹Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ

            # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ğ³Ğ¾Ğ´, Ğ¼ĞµÑÑÑ†, Ğ´ĞµĞ½ÑŒ
            signed_date_keys = [
                "content__award__relevantContractDates__signedDate",
                "content__IDV__relevantContractDates__signedDate",
                "content__OtherTransactionAward__contractDetail__relevantContractDates__signedDate",
                "content__OtherTransactionIDV__contractDetail__relevantContractDates__signedDate",
            ]
            signed_date = next(
                (contract[k] for k in signed_date_keys if k in contract and contract[k]), None)
            if not signed_date:
                raise ValueError(
                    f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ°! Ğ’ ĞºĞ¾Ğ½Ñ‚Ñ€Ğ°ĞºÑ‚Ğµ Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚ `signed_date`. ĞšĞ¾Ğ½Ñ‚Ñ€Ğ°ĞºÑ‚: {json.dumps(contract, indent=2)}")

            # Ğ Ğ°Ğ·Ğ±Ğ¸Ğ²Ğ°ĞµĞ¼ ÑÑ‚Ñ€Ğ¾ĞºÑƒ Ğ´Ğ°Ñ‚Ñ‹ "YYYY-MM-DD HH:MM:SS" Ğ¸ Ğ¸Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ
            date_parts = signed_date.split(" ")[0].split(
                "-")  # Ğ‘ĞµÑ€Ñ‘Ğ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ "YYYY-MM-DD"
            partition_year = int(date_parts[0])
            partition_month = int(date_parts[1])
            partition_day = int(date_parts[2])
            # ğŸ”„ ĞŸÑ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·ÑƒĞµĞ¼ Ğ±ÑƒĞ»ĞµĞ²Ñ‹ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ
            contract = process_booleans(contract, bool_fields)

            # ğŸ“¦ Ğ¤Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞµĞ¼ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ
            contract_data = extract_contract_data(
                contract, partition_year, partition_month, partition_day)

            # âš ï¸ ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, ĞµÑÑ‚ÑŒ Ğ»Ğ¸ Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ñ… Ğ½ĞµÑ‚ Ğ² `columns`
            log_missing_keys(contract, columns, file_path)

            batch.append(contract_data)

        # ğŸš€ Ğ’ÑÑ‚Ğ°Ğ²ĞºĞ° Ğ² ClickHouse
        if batch:
            # ğŸ”¹ Ğ’ÑÑ‚Ğ°Ğ²ĞºĞ° Ğ² ClickHouse
            insert_batch_with_retry(client, "raw_contracts", batch, columns)
            total_inserted += len(batch)
            print(f"âœ… Ğ’ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ {total_inserted} Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹.")
            gc.collect()
            time.sleep(3)  # ĞŸÑ€ĞµĞ´Ğ¾Ñ‚Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµĞ¼ Ğ¿ĞµÑ€ĞµĞ³Ñ€ÑƒĞ·ĞºÑƒ

        # ğŸ”„ ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ ÑÑ‚Ğ°Ñ‚ÑƒÑ Ğ² MySQL Ğ¿Ğ¾ÑĞ»Ğµ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ Ğ²ÑÑ‚Ğ°Ğ²ĞºĞ¸
        update_status(file_id, "clickhouse_loaded", total_inserted)

    # ğŸ”” ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ñ‹ Ğ»Ğ¸ Ğ²ÑĞµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ
    if total_inserted >= expected_records:
        update_status(file_id, "clickhouse_loaded", total_inserted)
    else:
        update_status(file_id, "clickhouse_load_failed", total_inserted)


# ğŸ”„ Ğ—Ğ°Ğ¿ÑƒÑĞº
if __name__ == "__main__":
    file_data = get_next_file()

    if file_data:
        process_data_and_insert(file_data)
    else:
        print("ğŸ‰ ĞĞµÑ‚ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ´Ğ»Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸. Ğ—Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ğµ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹.")
